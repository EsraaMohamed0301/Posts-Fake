{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRuhMYjQ_DcC"
      },
      "source": [
        "# **Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2aHuQz5DTKc"
      },
      "source": [
        "**Q1) What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?**\n",
        "\n",
        "* **What is the difference between Character n-gram and Word n-gram?**\n",
        "  > * **Character n-grams**\n",
        "     * Character n-grams are found in text documents by representing the document as a sequence of characters. \n",
        "     * Character n-grams have proven to be of high quality for authorship attribution.\n",
        "     * Character n-grams are including whitespaces and punctuation.\n",
        "     * example, a character 4-gram model results in the following tokens: [_It_], [It_i], [t_is], [_is_], [is_a], [s_a_], [_a_s].\n",
        "  * **Word n-grams**\n",
        "     * Word n-grams are found in text documents by representing the document as a sequence of words. \n",
        "     * example, a character 1-gram model results in the following tokens: [hello], [like], [eat].\n",
        "\n",
        "\n",
        "\n",
        "* **Which one tends to suffer more from the OOV issue?**\n",
        "> The word is OOV. An Out-Of-Vocabulary (OOV) Word is a Linguistic Unit or a token that does not appear in training vocabulary or document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZk3kLfOrQPO"
      },
      "source": [
        "**Q2) What is the difference between stop word removal and stemming? Are these techniques language-dependent?**\n",
        "\n",
        "* **What is the difference between stop word removal and stemming?**\n",
        "> * **Stop words:**\n",
        "    * Stop words are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc.\n",
        "    * Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information.\n",
        "  * **Stemming:**\n",
        "    * Stemming algorithms work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word. Examples of stemming in English are \"studies\" when we use the stemming it will be \"studi\".\n",
        "\n",
        "\n",
        "\n",
        "* **Are these techniques language-dependent?**\n",
        "> yes, the stop words and the stemming are language-dependent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFmcLacfKBZc"
      },
      "source": [
        "**Q3) Is tokenization techniques language dependent? Why?**\n",
        "> yes, tokenization is heavily dependent on language. Each language can have various linguistic rules and exceptions. Languages such as English identify token boundaries via whitespace and punctuation, but other languages such as Chinese require a more complex segmenter to extract tokens from a stream of text that does not contain any whitespaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXPKbakjOypR"
      },
      "source": [
        "**Q4) What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?**\n",
        "> * **What is the difference between count vectorizer and tf-idf vectorizer?**\n",
        "    * The time it takes to create the count. Vectorizer is much lesser as compared to your hashing function or the tf-idf representation.\n",
        "    * CountVectorizer: Counts the frequency of all words in our corpus, sorts them and grabs the most recurring features (using max_features hyperparameter). But these results are mostly biased and our model might loose out on some of the important less frequent features. These are all boolean values. Ex. SEO People used to take advantage of this.\n",
        "    * TFIDFVectorizer: TFIDF is a statistical measure said to have fixed the issues with CountVectorizer in some way. It consists of 2 parts, TF (Term Frequency) multiplied with IDF (Inverse Document Frequency). The main intuition being some words that appear frequently in 1 document and less frequently in other documents could be considered as providing extra insight for that 1 document and could help our model learn from this additional piece of information. In short, common words are penalized. These are relative frequencies identified as floating point numbers.      \n",
        "* **Would it be feasible to use all possible n-grams? If not, how should you select them?**\n",
        ">  * No, This will make it very difficult to assign likelihoods that capture the target of our analysis.\n",
        "  * it will depand on the model and i will try different n to decide the best n. because If we consider a chunk size of n=2, our results include “The reporters,” “the President,” “the United,” and “the room.” While not perfect, this model successfully identifies three of the relevant entities as candidates in a lightweight fashion.\n",
        "On the other hand, a model based on the small n-gram window of 2 would fail to capture some of the nuance of the original text. For instance, if our sentence is from a text that references multiple heads of state, “the President” could be somewhat ambiguous. In order to capture the entirety of the phrase “the President of the United States,” "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOXXtMFxiyMP"
      },
      "source": [
        "# **Problem Formulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VhHuObDLnsE"
      },
      "source": [
        "## **Define the problem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu3a6xp2bf9L"
      },
      "source": [
        "* Because of the rise of social networks and their involvement in other spheres such as politics, false information on the Internet has produced a slew of social issues.\n",
        "* We are going to predict if a specific reddit post is fake news or not, by looking at its title."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1FDf-taLwws"
      },
      "source": [
        "## **What is the input?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsRBoadNh4um"
      },
      "source": [
        "The input is the text feature. it contains various forms of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wBLUiHhL00D"
      },
      "source": [
        "## **What is the output?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0BS7qIgonx0"
      },
      "source": [
        "If a specific reddit post is fake news or not.\n",
        "In the dataset, the label column is output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfCzc5IBL41M"
      },
      "source": [
        "## **What data mining function is required?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsLx29Ogon57"
      },
      "source": [
        "In this case, it will be binary Classification that separates data points into different classes (fake or not / 0 or 1) which If a specific reddit post is fake news or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj3_r7c2L8Qy"
      },
      "source": [
        "## **What could be the challenges?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJlj74yooAs"
      },
      "source": [
        "* The data contains various forms of words.\n",
        "* The datasets have outliers values.\n",
        "* predict a specific reddit post is fake news or not, by looking at its title."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9e_kyFjMAKD"
      },
      "source": [
        "## **What is the impact?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hLc4Dt1qBLt"
      },
      "source": [
        "When I create a new system and give it a Feature, it can decide whether If a specific reddit post is fake news or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnFzpJWjqBOj"
      },
      "source": [
        "## **What is an ideal solution?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sAlF3TN1SZP"
      },
      "source": [
        "According to my subsequent attempts, Bayesian Search and Random Forest Classifier with Cross Validation. is the best approach because it provides me the highest kaggle score.\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.87476\n",
        "        * Private score: 0.87632\n",
        "\n",
        "\n",
        "\n",
        "The Bayesian Search use of intelligence to pick the next set of hyperparameters which will improve the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN2VApPL6xmi"
      },
      "source": [
        "# **Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ejMf2lxKKBL"
      },
      "source": [
        "## **Steps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ktcYEuvrsOj"
      },
      "source": [
        "### **What preprocessing steps are used?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okBPzKVgqmo8"
      },
      "source": [
        "* Remove outliers.\n",
        "* Cleaning the text.\n",
        "* Compute the frequency of the words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTW_FVARqBRD"
      },
      "source": [
        "### **What is the experimental protocol used and how was it carried out?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3sKd5d3r2Ra"
      },
      "source": [
        "* Read the data using the function \"read_csv\"\n",
        "* Cleaning the text by I'll remove any html tags, digits, single letter chars, stopwords, punctuation, the noise data, convert all whitespaces to single wspace and make stemming. \n",
        "* I will split the data to use Holdout method is split the training dataset to training data and validation data using \"train_test_split\".\n",
        "* I use Cross validation for training the model well.\n",
        "* Determine the optimal values for a given model by using GridSearch, RandomSearch and BayesianSearch.\n",
        "* I use Xgboost, Random Forest and Logistic Regression to fit the model.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTWvFD-BJkZt"
      },
      "source": [
        "## **Important Libraries**\n",
        "I will install a package and import several libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEwfsKb1264c",
        "outputId": "345adb37-04c5-468e-e6cc-80244d193820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 100 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL6sTsVreLYu"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import holoviews as hv\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRYfNfOteLbk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from bokeh.models import NumeralTickFormatter\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "# SelectKBest use for Select features according to the k highest scores. mutual_info_classif utilize the mutual information.\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "\n",
        "# Provides train/test indices to split data into train/test sets\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "\n",
        "# import warnings to prevent show warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KT8qa067OSU"
      },
      "source": [
        "## **Read Data**\n",
        "I Will connect to the drive and load and read train and test files from there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GB1yu3M7OY2"
      },
      "source": [
        "I'll use the read csv function to read the data. It may read any delimited text file and change the delimiter by using the sep option.\n",
        "\n",
        "I'm going to read the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqm4Wgqj7aBt",
        "outputId": "919c06ed-1ed6-4c06-a313-cd19348dcc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect to my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrGuoTWs7kIF"
      },
      "outputs": [],
      "source": [
        "# reading the training dataset \n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Data Mining/Compition 3/xy_train.csv', index_col='id') \n",
        "# df_train = pd.read_csv('xy_train.csv', index_col='id') \n",
        "# reading the testing dataset \n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Data Mining/Compition 3/x_test.csv', index_col='id') \n",
        "# df_test = pd.read_csv('x_test.csv', index_col='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtwhOaWJ9DmG",
        "outputId": "e3482ba3-61b7-461f-e03e-ca2ad7b10b27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \n",
              "id             \n",
              "265723      0  \n",
              "284269      0  \n",
              "207715      0  \n",
              "551106      0  \n",
              "8584        0  \n",
              "...       ...  \n",
              "70046       0  \n",
              "189377      1  \n",
              "93486       0  \n",
              "140950      0  \n",
              "34509       1  \n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f7c50cd-3712-44de-a1ba-642d4d1e1c69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f7c50cd-3712-44de-a1ba-642d4d1e1c69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f7c50cd-3712-44de-a1ba-642d4d1e1c69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f7c50cd-3712-44de-a1ba-642d4d1e1c69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# show the training data\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYDfIKpA9EGN",
        "outputId": "77b661c6-d847-45ee-efba-304970f68cf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text\n",
              "id                                                                                    \n",
              "0                                                                           stargazer \n",
              "1                                                                                 yeah\n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video\n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility\n",
              "4                                                         \"Believers\" - Hezbollah 2011\n",
              "...                                                                                ...\n",
              "59146                                                Bicycle taxi drivers of New Delhi\n",
              "59147                             Trump blows up GOP's formula for winning House races\n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised\n",
              "59149                                 Deep down he always wanted to be a ballet dancer\n",
              "59150                        Toddler miraculously survives 6-story fall landing on car\n",
              "\n",
              "[59151 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcd33fe1-0e54-4b66-b42d-26fe3bcd946f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcd33fe1-0e54-4b66-b42d-26fe3bcd946f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcd33fe1-0e54-4b66-b42d-26fe3bcd946f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcd33fe1-0e54-4b66-b42d-26fe3bcd946f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# show the testing data\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF6xW6IE9SGM",
        "outputId": "d837c7a1-10c6-40e6-ce95-01c38a40dfe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# check the data have the null values in training data\n",
        "df_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQC3FIKF9UiN",
        "outputId": "b90a9487-89c8-4549-85e8-97eb8773531c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# check the data have the null values in testing data\n",
        "df_test.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFYa0Al49XG9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFns9ZM09bVN"
      },
      "source": [
        "## **Cleaning and preprocessing**\n",
        "\n",
        "Create Function for remove any html tags, remove any digits, remove any single letter chars, convert all whitespaces to single wspace, make all lowercase words, remove any stopwords, remove any punctuation and make stemming. remove the noise data in training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dfgmoz39cF8",
        "outputId": "b147d56b-5329-451c-f05f-09b7b8a79ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# required package for tokenization.\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords')\n",
        "\n",
        "# for stemming algorithm\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "# Make Function to clean text\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "        - return the clean text\n",
        "    \"\"\"\n",
        "    re_wspace = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    re_tags = re.compile(r\"<[^>]+>\")\n",
        "    re_ASII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    re_single_char = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        re_ASII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        re_single_char = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(re_tags, \" \", text)\n",
        "    text = re.sub(re_ASII, \" \", text)\n",
        "    text = re.sub(re_single_char, \" \", text)\n",
        "    text = re.sub(re_wspace, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_hk9fBI_6Fn",
        "outputId": "faf9c4bc-c3bd-41f4-a7c3-b027d7cb0802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 46.5 s, sys: 188 ms, total: 46.7 s\n",
            "Wall time: 1min 1s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Clean texts training data \n",
        "df_train[\"text_clean\"] = df_train.loc[df_train[\"text\"].str.len() > 0, \"text\"] # get all text data the length it greater than 0 in training data\n",
        "# call clean_text of method to apply it on text_clean feature in traing data\n",
        "df_train[\"text_clean\"] = df_train[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x  # check if text is instance of string\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pV3cs2dANJe",
        "outputId": "a7f0b7c9-83ac-4ce2-ef95-8c185740caa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \\\n",
              "id              \n",
              "265723      0   \n",
              "284269      0   \n",
              "207715      0   \n",
              "551106      0   \n",
              "8584        0   \n",
              "...       ...   \n",
              "70046       0   \n",
              "189377      1   \n",
              "93486       0   \n",
              "140950      0   \n",
              "34509       1   \n",
              "\n",
              "                                                                                                 text_clean  \n",
              "id                                                                                                           \n",
              "265723  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "284269  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "207715  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "551106  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "8584    obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                     ...  \n",
              "70046                                                        finish sniper simo yh invas finland ussr color  \n",
              "189377                                               nigerian princ scam took kansa man year later get back  \n",
              "93486                                                          safe smoke marijuana pregnanc surpris answer  \n",
              "140950                                               julius caesar upon realiz everyon room knife except bc  \n",
              "34509                                         jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edc7b32a-42b2-481c-aee8-5e0ec8b77a5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edc7b32a-42b2-481c-aee8-5e0ec8b77a5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-edc7b32a-42b2-481c-aee8-5e0ec8b77a5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-edc7b32a-42b2-481c-aee8-5e0ec8b77a5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# show the training data\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHXaRnQAAEHt",
        "outputId": "917a4087-9c19-401a-f9a9-5bafae2d36be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14 s, sys: 78.8 ms, total: 14.1 s\n",
            "Wall time: 14.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Clean texts testing data\n",
        "df_test[\"text_clean\"] = df_test.loc[df_test[\"text\"].str.len() > 0, \"text\"] # get all text data the length it greater than 0 in testing data\n",
        "# call clean_text of method to apply it on text_clean feature in testing data\n",
        "df_test[\"text_clean\"] = df_test[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x  # check if text is instance of string\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8VIDUdxAI-u",
        "outputId": "68f6f49e-09f0-4e3f-cbd8-2b342e92827f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                  text  \\\n",
              "id                                                                                       \n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                            text_clean  \n",
              "id                                                      \n",
              "0                                              stargaz  \n",
              "1                                                 yeah  \n",
              "2       pd phoenix car thief get instruct youtub video  \n",
              "3                 trump accus iran one problem credibl  \n",
              "4                                     believ hezbollah  \n",
              "...                                                ...  \n",
              "59146                     bicycl taxi driver new delhi  \n",
              "59147             trump blow gop formula win hous race  \n",
              "59148  napoleon return exil island elba march colouris  \n",
              "59149                    deep alway want ballet dancer  \n",
              "59150       toddler miracul surviv stori fall land car  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa33a46c-9b63-4915-a89d-46f98e185d5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycl taxi driver new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>trump blow gop formula win hous race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>napoleon return exil island elba march colouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep alway want ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>toddler miracul surviv stori fall land car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa33a46c-9b63-4915-a89d-46f98e185d5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa33a46c-9b63-4915-a89d-46f98e185d5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa33a46c-9b63-4915-a89d-46f98e185d5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# show the testing data\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZv5CEiRBfNH",
        "outputId": "a9b6bdde-18a5-4e18-b729-b8fe74300541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.536200\n",
              "1    0.459933\n",
              "2    0.003867\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Distribution of ratings\n",
        "df_train[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnKqr9dEBgO-"
      },
      "outputs": [],
      "source": [
        "# remove any values of label have 2\n",
        "df_train = df_train[df_train[\"label\"] != 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52TjWFuHCHgv",
        "outputId": "d0a23fcd-319d-4492-87fc-29b1e498e72f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                       text  \\\n",
              "id                                                                                                            \n",
              "265723  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "284269  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "207715  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                     ...   \n",
              "70046                 Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "189377                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "93486                 Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "140950                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "34509                 Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "        label  \\\n",
              "id              \n",
              "265723      0   \n",
              "284269      0   \n",
              "207715      0   \n",
              "551106      0   \n",
              "8584        0   \n",
              "...       ...   \n",
              "70046       0   \n",
              "189377      1   \n",
              "93486       0   \n",
              "140950      0   \n",
              "34509       1   \n",
              "\n",
              "                                                                                                 text_clean  \n",
              "id                                                                                                           \n",
              "265723  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "284269  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "207715  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "551106  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "8584    obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                     ...  \n",
              "70046                                                        finish sniper simo yh invas finland ussr color  \n",
              "189377                                               nigerian princ scam took kansa man year later get back  \n",
              "93486                                                          safe smoke marijuana pregnanc surpris answer  \n",
              "140950                                               julius caesar upon realiz everyon room knife except bc  \n",
              "34509                                         jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[59768 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a816752f-b9c2-411d-bceb-12feb3e529d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59768 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a816752f-b9c2-411d-bceb-12feb3e529d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a816752f-b9c2-411d-bceb-12feb3e529d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a816752f-b9c2-411d-bceb-12feb3e529d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# show the training data\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y76-bSZXCIyN",
        "outputId": "c0c5e827-b999-4793-da5c-e9737825fab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538281\n",
              "1    0.461719\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Distribution of ratings\n",
        "df_train[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlFpCEECCmz9"
      },
      "outputs": [],
      "source": [
        "# set the tect_clean feature and label to values in training data \n",
        "X = df_train[\"text_clean\"]\n",
        "Y = df_train[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GSnNbXL4u4y"
      },
      "source": [
        "## **Functions**\n",
        "\n",
        "I'll do functions because I'll be using them a lot and don't want to repeat the code. such as create pipline and set multiple classifiers and fit them, predict the testing set and record the probability of prediction in csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H89Qxb9nbva0"
      },
      "outputs": [],
      "source": [
        "# Make a Function to Pipeline vectorizer and my_classifier\n",
        "# combine the vectorizer with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "\n",
        "def create_fit_pipeline(my_classifier):\n",
        "  full_pipeline = Pipeline(\n",
        "      steps=[\n",
        "          (\"vectorizer\", TfidfVectorizer(norm=\"l2\")), \n",
        "          ('my_classifier', my_classifier)\n",
        "      ]\n",
        "  )\n",
        "  # The pipeline object can be used like any sk-learn model and training it \n",
        "  full_pipeline = full_pipeline.fit(X, Y)\n",
        "  return full_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcNxYeCrfQWs"
      },
      "outputs": [],
      "source": [
        "# Make Funiction to prediction the pipeline\n",
        "def predict_pipeline(full_pipeline):\n",
        "  # prediction the df_test\n",
        "  y_pred = full_pipeline.predict(df_test)\n",
        "  # Show unique and count values\n",
        "  return pd.DataFrame(y_pred).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VgxFZ2hFByd"
      },
      "outputs": [],
      "source": [
        "# Make a Function for predict the testing data and save it in the csv file\n",
        "def predict_save_csv(search_model, classifier_name):\n",
        "  submission = pd.DataFrame()\n",
        "  submission['id'] = df_test.index\n",
        "  submission['label'] = search_model.predict_proba(df_test.text_clean)[:,1]\n",
        "  file_name = 'Compition_3_' + classifier_name + '.csv'\n",
        "  submission.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSrOxhJEoSLL"
      },
      "outputs": [],
      "source": [
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X, Y, train_size = 0.8, stratify = Y, random_state = 42)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKz00dGZODVc"
      },
      "source": [
        "### **Tuning Methods**\n",
        "\n",
        "Tuning Methods *(Grid Search, Random Search, Bayisen Search)* are available in the scikit-learn class model_selection. It can be initiated by creating an object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6LHOvU1PWsD"
      },
      "source": [
        "\n",
        "**Parameters of Tuning Methods *(Grid Search, Random Search, Bayisen Search)* method are:**\n",
        "* **estimator:** *(object)* a scikit-learn model.\n",
        "* **param_grid:** *(dict or list of dictionaries)* This enables searching over any sequence of parameter settings.\n",
        "* **scoring:** *(str, callable, list, tuple or dict)* Strategy to evaluate the performance of the cross-validated model on the test set.\n",
        "* **n_jobs:** *(int)* Number of jobs to run in parallel. \n",
        "  * `None` means 1.\n",
        "  * `-1` means using all processors.\n",
        "* **refit:** *(bool, str, or callable)* Refit an estimator using the best found parameters on the whole dataset.\n",
        "* **cv:** *(int, cross-validation generator or an iterable)* determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
        "\n",
        "  * None, to use the default 5-fold cross validation.\n",
        "  * integer, to specify the number of folds in a (Stratified)KFold.\n",
        "  * CV splitter.\n",
        "  * An iterable yielding (train, test) splits as arrays of indices.\n",
        "* **verbose:** *(int)* Controls the verbosity (Controll to show messages)\n",
        "  * `>1`: the computation time for each fold and parameter candidate is displayed.\n",
        "  * `>2` : the score is also displayed.\n",
        "  * `>3` : the fold and candidate parameter indexes are also displayed together with the starting time of the computation.\n",
        "* **error_score:** *(‘raise’ or numeric)* Value to assign to the score if an error occurs in estimator fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwhabHexNME0"
      },
      "source": [
        "#### **Grid Search**\n",
        "\n",
        "Grid search is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. The performance of a model significantly depends on the value of hyperparameters. \n",
        "\n",
        "Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLRer769joDO"
      },
      "source": [
        "I will create function to create object from Grid Search, fit them and get the best score.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fldkfb8xE_ON"
      },
      "outputs": [],
      "source": [
        "# Make Function to create and fit the Grid Search to pipeline\n",
        "\n",
        "def create_fit_grid_search(full_pipeline, param_grid, cv):\n",
        "  # cv means number of K-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs (on colab since we only have two cpu cores, we set it to 2)\n",
        "\n",
        "  grid_search = GridSearchCV(\n",
        "      full_pipeline, param_grid, cv=cv, verbose=1, n_jobs=2, \n",
        "      scoring='roc_auc') # create object GridSearchCV\n",
        "\n",
        "  grid_search.fit(X, Y) # train the gridsearch\n",
        "\n",
        "  print('best score {}'.format(grid_search.best_score_)) # print the best score of model\n",
        "  print('best score {}'.format(grid_search.best_params_)) # print the best hyperparameters of model\n",
        "  return grid_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vofseo-jZP8"
      },
      "source": [
        "#### **Random Search**\n",
        "\n",
        "Random search methods are stochastic approaches that rely entirely on the random sampling of a succession of points in the problem's feasible region, according to a predetermined probability distribution or sequence of probability distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPuNlLbxkSL2"
      },
      "source": [
        "I will create function to create object from Random Search, fit them and get the best score.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otoH3B5MV6IY"
      },
      "outputs": [],
      "source": [
        "# Make Function to create and fit the Random Search to pipeline\n",
        "\n",
        "def create_fit_random_search(full_pipeline, param_random, cv):\n",
        "  # cv= cv means cv-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs\n",
        "  # (on colab since we only have two cpu cores, we set it to 2)\n",
        "  random_search = RandomizedSearchCV(\n",
        "      full_pipeline, param_random, cv=cv, verbose=1, n_jobs=2, \n",
        "      # number of random trials\n",
        "      n_iter=5,\n",
        "      scoring='roc_auc')\n",
        "\n",
        "  random_search.fit(X, Y)\n",
        "\n",
        "  print('best score {}'.format(random_search.best_score_)) # print the best score of model\n",
        "  print('best score {}'.format(random_search.best_params_)) # print the best hyperparameters of model\n",
        "  return random_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkPmmDe4kMyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ16MMwKkV9s"
      },
      "source": [
        "#### **Bayesian Search**\n",
        "\n",
        "This model is called a **surrogate** for the objective function. The surrogate is much easier to optimize than the objective function and Bayesian methods work by finding the next set of hyperparameters to evaluate on the actual objective function by selecting hyperparameters that perform best on the surrogate function.\n",
        "\n",
        "Bayesian Search keeps track of previous assessment results, which they use to create a probabilistic model that maps hyperparameters to the likelihood of a score on the objective function.\n",
        "\n",
        "\\\n",
        "This method advocates the usage of intelligence to pick the next set of hyperparameters which will improve the model performance. We iteratively repeat this process until we converge to an optimum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L8wCYP-kNO_"
      },
      "source": [
        "I will create function to create object from Bayesian Search, fit them and get the best score.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ37X1_7oRhL"
      },
      "outputs": [],
      "source": [
        "# Make Function to create and fit the Bayesian Search to pipeline\n",
        "\n",
        "def create_fit_bayesian_search(full_pipeline, param_bayesian, cv):\n",
        "  # cv= cv means cv-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs\n",
        "  # (on colab since we only have two cpu cores, we set it to 2)\n",
        "    Bayes_search = BayesSearchCV(\n",
        "      full_pipeline, param_bayesian, cv=cv, verbose=1, n_jobs=2, \n",
        "      # number of Bayes trials\n",
        "      n_iter=5)\n",
        "\n",
        "    Bayes_search.fit(X, Y)\n",
        "\n",
        "    print('best score {}'.format(Bayes_search.best_score_)) # print the best score of model\n",
        "    print('best score {}'.format(Bayes_search.best_params_)) # print the best hyperparameters of model\n",
        "    return Bayes_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms0rr8M3G1wu"
      },
      "source": [
        "## **Different trials on model tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIwK8pWOHbIW"
      },
      "source": [
        "###  **1* XGBoost**\n",
        "\n",
        "\\\n",
        "\n",
        "This algorithm goes by lots of different names such as gradient boosting, multiple additive regression trees, stochastic gradient boosting or gradient boosting machines.\n",
        "\n",
        "A Gradient Boosting Decision Trees (GBDT) is a decision tree ensemble learning algorithm similar to random forest, **Ensemble learning algorithms** combine multiple machine learning algorithms to obtain a better model. **Random forest** uses to build full decision trees in parallel from random bootstrap samples of the data set. \n",
        "\n",
        "It is the top machine learning library for regression, classification, and ranking tasks.\n",
        "\n",
        "* It includes parallel tree boosting.\n",
        "* It supports regularization.\n",
        "* It is designed to handle missing data with its in-build features.\n",
        "* The user can run a cross-validation after each iteration. \n",
        "* It works well in small to medium dataset.\n",
        "* It is designed to be highly efficient, flexible and portable.\n",
        "* It has a distributed weighted quantile sketch algorithm to effectively handle weighted data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ12RYgLHjWG"
      },
      "source": [
        "To develop a model, the XGBoost classifier contains a lot of hyperparameters. I'll use some of them to assist us enhance the model and score.\n",
        "\n",
        "**The hyperparameters are:**\n",
        "* **learning_rate:** Learning rate reduces each tree's contribution by learning rate. Between learning rate and n estimators, there is a trade-off.\n",
        "* **n_estimators:** The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
        "* **subsample:** The percentage of samples that will be used to fit particular base learners. Stochastic Gradient Boosting occurs when the value is less than 1.0. The parameter n estimators interacts with subsample. Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
        "* **colsample_bytree:** Subsample ratio of columns when constructing each tree.\n",
        "*  **nthread:** Number of threads to use for loading data when parallelization is applicable. If -1, uses maximum threads available on the system.\n",
        "* **objective:** Specify the learning task and the corresponding learning objective or a custom objective function to be used.\n",
        "* **silent:** Whether print messages during construction.\n",
        "* **random_state:** Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random splitting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_25qCcsG5Yt",
        "outputId": "b9dcda10-72ba-4499-8f5d-5d5ff4094254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# for the create pipeline with my classifier is XGBoost Classifier\n",
        "full_pipeline_XGB = create_fit_pipeline(XGBClassifier(objective='binary:logistic', silent=True, random_state= 42))\n",
        "# prediction the pipeline\n",
        "predict_pipeline(full_pipeline_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88AFzZPFHwmO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAz1EOD25yu-"
      },
      "source": [
        "#### **1- Bayesian Search with Cross Validation**\n",
        "\n",
        "**using Bayesian Search and XGBoost Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqsZpTft-vb9"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "I'll utilise Cross Validation with Bayesian Search and XGBoost. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **objective:** binary:logistic\n",
        "* **silent:** True\n",
        "* **random_state:** 42\n",
        "* **analyzer:** word\n",
        "* **max_df:** 0.3\n",
        "* **min_df:** 30\n",
        "\n",
        "* **learning_rate:** 0.1\n",
        "* **n_estimators:** 1500\n",
        "* **subsample:** 0.8\n",
        "* **colsample_bytree:** 1.0\n",
        "* **nthread:** 9\n",
        "* **CV:** 3\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.754952\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.80636\n",
        "        * Private score: 0.80525\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Grid Search and Random Forest Classifier with Validation Set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgfgTwP--Km8"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for XGBoost Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_XGB = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    # 'vectorizer__ngram_range' : [(1, 2)],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30],\n",
        "    \n",
        "\n",
        "    'my_classifier__learning_rate' : [0.005, 0.001, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3],\n",
        "    'my_classifier__n_estimators' : [600,1000, 1100, 1500, 2000, 3000, 4000],\n",
        "    'my_classifier__nthread' : [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "#     'my_classifier__min_child_weight': [1, 5, 10],\n",
        "#     'my_classifier__gamma': [0.4, 0.5, 0.6, 1, 1.5, 2, 2.5, 3, 5],\n",
        "    'my_classifier__subsample': [0.05, 0.2, 0.3, 0.6, 0.8, 0.9],\n",
        "    'my_classifier__colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "#     'my_classifier__max_depth': np.arange(3, 20),\n",
        "#     'my_classifier__random_state' : [0, 1, 42, 15]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEmIeP1AwlXN",
        "outputId": "ed1276c6-9cd8-41d7-b454-3e8bd8f120f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "best score 0.7549524903552775\n",
            "best score OrderedDict([('my_classifier__colsample_bytree', 1.0), ('my_classifier__learning_rate', 0.1), ('my_classifier__n_estimators', 1500), ('my_classifier__nthread', 9), ('my_classifier__subsample', 0.8), ('vectorizer__analyzer', 'word'), ('vectorizer__max_df', 0.3), ('vectorizer__min_df', 30)])\n",
            "Best: 0.754952 using OrderedDict([('my_classifier__colsample_bytree', 1.0), ('my_classifier__learning_rate', 0.1), ('my_classifier__n_estimators', 1500), ('my_classifier__nthread', 9), ('my_classifier__subsample', 0.8), ('vectorizer__analyzer', 'word'), ('vectorizer__max_df', 0.3), ('vectorizer__min_df', 30)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_bayesian_search function and it will return bayesian_search for XGBoost and it will use the (X) and (Y)\n",
        "bayesian_search_XGB = create_fit_bayesian_search(full_pipeline_XGB, param_XGB, 3)\n",
        "print(\"Best: %f using %s\" % (bayesian_search_XGB.best_score_, bayesian_search_XGB.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500XUc90-Mc1"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_XGB, 'XGB_Bayesian_Cross')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmc9C8tdJsq-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnIqkK9OKMiQ"
      },
      "source": [
        "### **3* Random Forest**\n",
        "Random forests are a type of ensemble method. An ensemble method is a process in which numerous models are fitted and the results are combined for stronger predictions. While this provides great predictions, inference and explainability are often limited. Random forests are composed of a number of decision trees where the included predictors are chosen at random. The name comes from randomly building trees to make a forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4KQGBIpOpSr"
      },
      "source": [
        "We can create a random forest just like we created a decision tree, except now we are also specifying parameters that indicate how many trees should be in the forest, how we should subset the data items (the rows), and how we should subset the fields (the columns).\n",
        "\n",
        "In the following function definition, `n_estimators` defines the number of trees we want,` max_samples` defines how many rows to sample for training each tree, and `max_features` defines how many columns to sample at each split point (where 0.5 means “take half the total number of columns”). We can also specify when to stop splitting the tree nodes, effectively limiting the depth of the tree, by including the same `min_samples_leaf` parameter we used in the preceding section. Finally, we pass `n_jobs=-1` to tell sklearn to use all our CPUs to build the trees in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ygQLEf1KNLO"
      },
      "outputs": [],
      "source": [
        "# for the create pipeline with my classifier is RandomForestClassifier\n",
        "full_pipeline_Randomforst = create_fit_pipeline(RandomForestClassifier())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir3uUTUnLKOh"
      },
      "source": [
        "##### **1- Grid Search with Validation Set**\n",
        "\n",
        "**using Grid Search and Random Forest Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwmp0aiRYOr"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "I will use the Grid Search and Random Fores with Validation Set. I expect that it will give me the highest score, because the model try all possible values to know the optimal values, and fit the estimator (model) on your training set.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Random Fores classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "* **analyzer:** word\n",
        "* **max_df:** 0.3\n",
        "* **min_df:** 5\n",
        "* **range:** (1, 2)\n",
        "\n",
        "\n",
        "* **n_estimators:** 500\n",
        "* **criterion:** gini\n",
        "* **max_features:** 0.8\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "Scores:\n",
        "\n",
        "    \n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.86520\n",
        "        * Private score: 0.86613\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Random Search and Random Forest Classifier with Validation Set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV9fDOTcLeUY"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for RandomForestClassifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_RandomForest = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': np.arange(0.3, 0.8),\n",
        "    'vectorizer__min_df': range(5, 30, 5),\n",
        "    'vectorizer__ngram_range': [(1, 2)], \n",
        "\n",
        "\n",
        "\n",
        "    'my_classifier__n_estimators': range(500, 1000, 100),\n",
        "    'my_classifier__criterion' :['gini', 'entropy'],\n",
        "#     'my_classifier__max_features' : ['auto', 'sqrt', 'log2'],\n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    # 'my_classifier__max_depth': [100, 200, 400, 600, 2000]       \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKShwVQGy1nC",
        "outputId": "3bd9accb-36d7-492b-ab7e-a8716df88597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n",
            "best score nan\n",
            "best score {'my_classifier__criterion': 'gini', 'my_classifier__n_estimators': 500, 'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.3, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for RandomForestClassifier and it will use the use the (X) and (Y)\n",
        "grid_search_RandomForest = create_fit_grid_search(full_pipeline_Randomforst, param_RandomForest, pds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-rvyvkGLwef"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(grid_search_RandomForest, 'RF_Grid_Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S34BVPNM7AY"
      },
      "source": [
        "#### **2- Random Search with Validation Set**\n",
        "**using Random Search and Random Forest Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Gd77e_0H2A"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Random Search and Random Forest with Validation Set will be used. Because Random search works best for lower dimensional data and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Random Forest classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "* **analyzer:** word\n",
        "* **max_df:** 0.3\n",
        "* **min_df:** 25\n",
        "* **range:** (1, 2)\n",
        "\n",
        "\n",
        "* **n_estimators:** 600\n",
        "* **criterion:** entropy\n",
        "* **max_features:** log2\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.86488\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score:  0.86781\n",
        "        * Private score: 0.86734\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and Random Forest Classifier with Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2LqK8hYNIhQ",
        "outputId": "dd284672-e254-4d71-c67c-86e837d0fa72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n",
            "best score 0.8648842389918672\n",
            "best score {'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 25, 'vectorizer__max_df': 0.3, 'vectorizer__analyzer': 'word', 'my_classifier__n_estimators': 600, 'my_classifier__max_features': 'log2', 'my_classifier__criterion': 'entropy'}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_Random_search function and it will return Random_search for Random Forest and it will use the (X) and (Y)\n",
        "random_search_RF = create_fit_random_search(full_pipeline_Randomforst, param_RandomForest, pds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZASD6WNNZTP"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_RF, 'RF_random_Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02fZJ4kUK2q4"
      },
      "source": [
        "#### **3- Bayesian Search with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLKaOMBsSS4r"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "I'll utilise Cross Validation with Bayesian Search and XGBoost. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "* **analyzer:** word\n",
        "* **max_df:** 0.8\n",
        "* **min_df:** 10\n",
        "\n",
        "\n",
        "* **n_estimators:** 600\n",
        "* **criterion:** gini\n",
        "* **max_features:** log2\n",
        "* **CV:** 20\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.78195\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.87476\n",
        "        * Private score: 0.87632\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and Logistic Regression Classifier with Validation Set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMa8G3JQSdFs"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for RandomForestClassifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_RandomForest = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30],\n",
        "    # 'vectorizer__ngram_range': [(1, 2)], \n",
        "\n",
        "\n",
        "\n",
        "    'my_classifier__n_estimators': [500, 600, 700, 800, 900, 1000],\n",
        "    'my_classifier__criterion' :['gini', 'entropy'],\n",
        "    'my_classifier__max_features' : ['auto', 'sqrt', 'log2'],\n",
        "     # my_classifier__n_estimators points to my_classifier->n_estimators \n",
        "    # 'my_classifier__max_depth': [100, 200, 400, 600, 2000]       \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDUoYufvK8De",
        "outputId": "71c1a139-b7c6-46f9-c2c2-db38d7e0a815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "best score 0.781956480992555\n",
            "best score OrderedDict([('my_classifier__criterion', 'gini'), ('my_classifier__max_features', 'log2'), ('my_classifier__n_estimators', 600), ('vectorizer__analyzer', 'word'), ('vectorizer__max_df', 0.8), ('vectorizer__min_df', 10)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_Bayesian_search function and it will return Bayesian_search for XGBoost and it will use the (x_train) and (y_train)\n",
        "bayesian_search_RF = create_fit_bayesian_search(full_pipeline_Randomforst, param_RandomForest, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KX9YYa4Mk5g"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_RF, 'RF_bayesian_Cross')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y16gWCtPMuTZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7IChNKlMuV3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlUxGH47iBO-"
      },
      "source": [
        "### **4* Logistic Regression**\n",
        "\n",
        "Logistic regression is used to handle the classification problems.\n",
        "\n",
        "It is used in statistical software to understand the relationship between the dependent variable and one or more independent variables by estimating probabilities using a logistic regression equation.  \n",
        "\n",
        "It is often used for predictive analytics and modeling, and extends to applications in machine learning. Logistic regression is easier to implement, interpret, and very efficient to train. \n",
        "\n",
        "\\\n",
        "\n",
        "**There are three main types of logistic regression:**\n",
        " * **Binary regression** deals with two possible values, essentially: yes or no. \n",
        " * **Multinomial logistic regression** deals with three or more values.\n",
        " * **ordinal logistic regression** deals with three or more classes in a predetermined order. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHPiV1_7nSEO"
      },
      "source": [
        "To develop a model, the Logistic Regression classifier contains a lot of hyperparameters. I'll use some of them to assist us enhance the model and score.\n",
        "\n",
        "**The hyperparameters are:**\n",
        "* **penalty:** Used to specify the norm used in the penalization. The newton-cg and lbfgs solvers support only l2 penalties.\n",
        "   * `'none':` no penalty is added;\n",
        "   * `'l2':` add a L2 penalty term and it is the default choice;\n",
        "   * `'l1':` add a L1 penalty term;\n",
        "   * `'elasticnet':` both L1 and L2 penalty terms are added.\n",
        "\n",
        "* **C:** Inverse of regularization strength.\n",
        "* **solver:** *(‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’)* use in the optimization problem. Default is ‘lbfgs’.\n",
        "  * `For small datasets, ‘liblinear’` is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones;\n",
        "  * `For multiclass problems,` only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss;\n",
        "  * `‘liblinear’` is limited to one-versus-rest schemes.\n",
        "* **random_state:** Used when solver == ‘sag’, ‘saga’ or ‘liblinear’ to shuffle the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7Hu-63irD2A"
      },
      "outputs": [],
      "source": [
        "# for the create pipeline with my classifier is Logistic Regression Classifier\n",
        "full_pipeline_Log = create_fit_pipeline(LogisticRegression(random_state = 42))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2* Random Search**"
      ],
      "metadata": {
        "id": "mLB6V8JDFbw9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98ajnD7idLs"
      },
      "source": [
        "##### **1- Random Search With Cross Validation**\n",
        "\n",
        "**using Random Search and Logistic Regression Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKC3NgMeidLt"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Random Search and Logistic Regression with Cross Validation will be used. Because Random search works best for lower dimensional data and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Logistic Regression classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "\n",
        "* **analyzer:** word\n",
        "* **max_df:** 0.4\n",
        "* **min_df:** 10\n",
        "\n",
        "\n",
        "\n",
        "* **penalty:** l2\n",
        "* **C:** 1\n",
        "* **solver:** sag\n",
        "\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.86863\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.82753\n",
        "        * Private score: 0.82932\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Random Search and Logistic Regressio Classifier with Validation Set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnyi1nIDsoWg"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPf8torZrakg",
        "outputId": "27c8f544-6bc3-4ed5-df9f-0f6f5224a78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 5 candidates, totalling 100 fits\n",
            "best score 0.8686367046931786\n",
            "best score {'vectorizer__min_df': 10, 'vectorizer__max_df': 0.4, 'vectorizer__analyzer': 'word', 'my_classifier__solver': 'sag', 'my_classifier__penalty': 'l2', 'my_classifier__C': 1}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "random_search_Log = create_fit_random_search(full_pipeline_Log, param_Log, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJVSsFAcidLt"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_Log, 'Log_Random_Cross')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JONOPF_2D4hL"
      },
      "source": [
        "##### **2- Random Search With Validation Set**\n",
        "\n",
        "**using Random Search and Logistic Regression Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UmAwk6rD4hM"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Random Search and Logistic Regression with Validation set will be used. Because Random search works best for lower dimensional data and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Logistic Regression classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "\n",
        "* **analyzer:** char\n",
        "* **max_df:** 0.8\n",
        "* **min_df:** 50\n",
        "\n",
        "\n",
        "\n",
        "* **penalty:** l2\n",
        "* **C:** 0.1\n",
        "* **solver:** sag\n",
        "\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.5558\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.56054\n",
        "        * Private score: 0.56428\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and Logistic Regressio Classifier with Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"char\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1, 2, 2.5],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ],
      "metadata": {
        "id": "x4oUmcL1EKjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a6ea7a-b654-4c5e-bc4c-d753bf363449",
        "id": "g8hSDnCcD4hM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 5 candidates, totalling 5 fits\n",
            "best score 0.555813279350152\n",
            "best score {'vectorizer__min_df': 50, 'vectorizer__max_df': 0.8, 'vectorizer__analyzer': 'char', 'my_classifier__solver': 'saga', 'my_classifier__penalty': 'l2', 'my_classifier__C': 0.1}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "random_search_Log = create_fit_random_search(full_pipeline_Log, param_Log, pds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKjh9WV3D4hM"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_Log, 'Log_Random_Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2* Bayesian Search**"
      ],
      "metadata": {
        "id": "oUB3KaGsI5jk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG1V1-PXtJ2f"
      },
      "source": [
        "##### **1- Bayesian Search With Cross Validation**\n",
        "\n",
        "**using Bayesian Search and Logistic Regression Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMIc0Pm3tJ2f"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Bayesian Search and Logistic Regression with Cross Validation will be used. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Logistic Regression classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "\n",
        "* **analyzer:** word\n",
        "* **max_df:** 0.4\n",
        "* **min_df:** 30\n",
        "\n",
        "\n",
        "* **penalty:** none\n",
        "* **C:** 0.01\n",
        "* **solver:** sag\n",
        "\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.77178\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.82408\n",
        "        * Private score: 0.82425\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALV-0zK91q3e"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"word\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqy25LoNtJ2f",
        "outputId": "d410cc15-404b-49c9-9a9c-de47c67ca558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "best score 0.7717839239191628\n",
            "best score OrderedDict([('my_classifier__C', 0.01), ('my_classifier__penalty', 'none'), ('my_classifier__solver', 'sag'), ('vectorizer__analyzer', 'word'), ('vectorizer__max_df', 0.4), ('vectorizer__min_df', 30)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "bayesian_search_Log = create_fit_bayesian_search(full_pipeline_Log, param_Log, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ySpglMtJ2f"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_Log, 'Log_Bayesian_Cross')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RICqZOVLMuY9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0irPcmVLMua3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7P4kqJgAjtr"
      },
      "source": [
        "##### **2- Bayesian Search With Validation Set**\n",
        "\n",
        "**using Bayesian Search and Logistic Regression Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HD00yEQDwW7"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Bayesian Search and Logistic Regression with Validation Set will be used. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Logistic Regression classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "\n",
        "\n",
        "* **analyzer:** char\n",
        "* **max_df:** 0.7\n",
        "* **min_df:** 40\n",
        "\n",
        "\n",
        "* **penalty:** none\n",
        "* **C:** 0.04\n",
        "* **solver:** sag\n",
        "\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.54893\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.55407\n",
        "        * Private score: 0.55859\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UORBCXmPMudZ"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'vectorizer__analyzer': [\"char\"], \n",
        "    'vectorizer__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
        "    'vectorizer__min_df': [5, 10, 15, 20, 25, 30, 35, 40, 50],\n",
        "    \n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nYjsajjMufq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad12faf-5cf2-44d9-a728-9129d3cc546c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.5489375941107579\n",
            "best score OrderedDict([('my_classifier__C', 0.04), ('my_classifier__penalty', 'none'), ('my_classifier__solver', 'sag'), ('vectorizer__analyzer', 'char'), ('vectorizer__max_df', 0.7), ('vectorizer__min_df', 40)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "bayesian_search_Log = create_fit_bayesian_search(full_pipeline_Log, param_Log, pds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_svaInVWMuh3"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_Log, 'Log_Bayesian_Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZUypMaHMvEP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkkH0cGwMvGw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IKsWLWJMvJP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGfQpC4UMvMP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YacvS9RcMynu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SRuhMYjQ_DcC",
        "ZOXXtMFxiyMP",
        "0VhHuObDLnsE",
        "M1FDf-taLwws",
        "7wBLUiHhL00D",
        "KfCzc5IBL41M",
        "aj3_r7c2L8Qy",
        "O9e_kyFjMAKD",
        "bnFzpJWjqBOj",
        "-ejMf2lxKKBL",
        "_ktcYEuvrsOj",
        "VTW_FVARqBRD",
        "sTWvFD-BJkZt",
        "0KT8qa067OSU",
        "sFns9ZM09bVN",
        "5GSnNbXL4u4y",
        "iKz00dGZODVc",
        "PwhabHexNME0",
        "mZ16MMwKkV9s",
        "gnIqkK9OKMiQ",
        "Ir3uUTUnLKOh",
        "7S34BVPNM7AY",
        "02fZJ4kUK2q4",
        "GlUxGH47iBO-",
        "JONOPF_2D4hL",
        "oUB3KaGsI5jk",
        "FG1V1-PXtJ2f",
        "Y7P4kqJgAjtr"
      ],
      "name": "DM_Compition_3_With_Doc_Final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}